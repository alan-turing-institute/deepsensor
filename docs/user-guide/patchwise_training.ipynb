{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patchwise Training\n",
    "\n",
    "Environmental data can sometimes span large spatial areas. For example:\n",
    "\n",
    "- Modelling tasks based on data that span the entire globe\n",
    "- Modelling tasks with high-resolution data\n",
    "\n",
    "In such cases, training and inference with a ConvNP over the entire region of data may be computationally prohibitive. However, we can resort to patchwise training, where the `TaskLoader` does not provide data of the entire region but instead creates smaller patches that are computationally feasible.\n",
    "\n",
    "The goal of the notebook is to demonstrate patchwise training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.captureWarnings(True)\n",
    "\n",
    "import deepsensor.torch\n",
    "from deepsensor.model import ConvNP\n",
    "from deepsensor.train import Trainer, set_gpu_default_device\n",
    "from deepsensor.data import DataProcessor, TaskLoader, construct_circ_time_ds\n",
    "from deepsensor.data.sources import (\n",
    "    get_era5_reanalysis_data,\n",
    "    get_earthenv_auxiliary_data,\n",
    "    get_gldas_land_mask,\n",
    ")\n",
    "\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/data config\n",
    "data_range = (\"2010-01-01\", \"2019-12-31\")\n",
    "train_range = (\"2010-01-01\", \"2018-12-31\")\n",
    "val_range = (\"2019-01-01\", \"2019-12-31\")\n",
    "date_subsample_factor = 2\n",
    "extent = \"north_america\"\n",
    "era5_var_IDs = [\"2m_temperature\"]\n",
    "lowres_auxiliary_var_IDs = [\"elevation\"]\n",
    "cache_dir = \"../../.datacache\"\n",
    "deepsensor_folder = \"../deepsensor_config/\"\n",
    "verbose_download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ERA5 data from Google Cloud Storage... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:02<00:00, 50.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 GB loaded in 2.78 s\n"
     ]
    }
   ],
   "source": [
    "era5_raw_ds = get_era5_reanalysis_data(\n",
    "    era5_var_IDs,\n",
    "    extent,\n",
    "    date_range=data_range,\n",
    "    cache=True,\n",
    "    cache_dir=cache_dir,\n",
    "    verbose=verbose_download,\n",
    "    num_processes=8,\n",
    ")\n",
    "lowres_aux_raw_ds = get_earthenv_auxiliary_data(\n",
    "    lowres_auxiliary_var_IDs,\n",
    "    extent,\n",
    "    \"100KM\",\n",
    "    cache=True,\n",
    "    cache_dir=cache_dir,\n",
    "    verbose=verbose_download,\n",
    ")\n",
    "land_mask_raw_ds = get_gldas_land_mask(\n",
    "    extent, cache=True, cache_dir=cache_dir, verbose=verbose_download\n",
    ")\n",
    "\n",
    "data_processor = DataProcessor(x1_name=\"lat\", x2_name=\"lon\")\n",
    "era5_ds = data_processor(era5_raw_ds)\n",
    "lowres_aux_ds, land_mask_ds = data_processor(\n",
    "    [lowres_aux_raw_ds, land_mask_raw_ds], method=\"min_max\"\n",
    ")\n",
    "\n",
    "dates = pd.date_range(era5_ds.time.values.min(), era5_ds.time.values.max(), freq=\"D\")\n",
    "doy_ds = construct_circ_time_ds(dates, freq=\"D\")\n",
    "lowres_aux_ds[\"cos_D\"] = doy_ds[\"cos_D\"]\n",
    "lowres_aux_ds[\"sin_D\"] = doy_ds[\"sin_D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gpu_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise TaskLoader and ConvNP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskLoader(3 context sets, 1 target sets)\n",
      "Context variable IDs: (('2m_temperature',), ('GLDAS_mask',), ('elevation', 'cos_D', 'sin_D'))\n",
      "Target variable IDs: (('2m_temperature',),)\n"
     ]
    }
   ],
   "source": [
    "task_loader = TaskLoader(\n",
    "    context=[era5_ds, land_mask_ds, lowres_aux_ds],\n",
    "    target=era5_ds,\n",
    ")\n",
    "task_loader.load_dask()\n",
    "print(task_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_yc inferred from TaskLoader: (1, 1, 3)\n",
      "dim_yt inferred from TaskLoader: 1\n",
      "dim_aux_t inferred from TaskLoader: 0\n",
      "internal_density inferred from TaskLoader: 400\n",
      "encoder_scales inferred from TaskLoader: [0.0012499999720603228, 0.0012499999720603228, 0.00416666641831398]\n",
      "decoder_scale inferred from TaskLoader: 0.0025\n"
     ]
    }
   ],
   "source": [
    "# Set up model\n",
    "model = ConvNP(data_processor, task_loader, unet_channels=(32, 32, 32, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define how Tasks are generated\n",
    "\n",
    "For the purpose of this notebook, we will use a random patchwise training strategy for our training tasks and a sliding window patch strategy for validation and testing to make sure we cover the entire region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_training_tasks(dates, progress=True):\n",
    "    tasks = []\n",
    "    for date in tqdm_notebook(dates, disable=not progress):\n",
    "        tasks_per_date = task_loader(\n",
    "            date,\n",
    "            context_sampling=[\"all\", \"all\", \"all\"],\n",
    "            target_sampling=\"all\",\n",
    "            patch_strategy=\"random\",\n",
    "            patch_size=(0.4, 0.4),\n",
    "            num_samples_per_date=2,\n",
    "        )\n",
    "        tasks.extend(tasks_per_date)\n",
    "    return tasks\n",
    "\n",
    "\n",
    "def gen_validation_tasks(dates, progress=True):\n",
    "    tasks = []\n",
    "    for date in tqdm_notebook(dates, disable=not progress):\n",
    "        tasks_per_date = task_loader(\n",
    "            date,\n",
    "            context_sampling=[\"all\", \"all\", \"all\"],\n",
    "            target_sampling=\"all\",\n",
    "            patch_strategy=\"sliding\",\n",
    "            patch_size=(0.5, 0.5),\n",
    "            stride=(1,1)\n",
    "        )\n",
    "        tasks.extend(tasks_per_date)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate validation tasks for testing generalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a4044f573a45578ae505a11d3a7bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n",
      "Number of patches per date using sliding window method 4\n"
     ]
    }
   ],
   "source": [
    "val_dates = pd.date_range(val_range[0], val_range[1])[::date_subsample_factor]\n",
    "val_tasks = gen_validation_tasks(val_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with the Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val_rmse(model, val_tasks):\n",
    "    errors = []\n",
    "    target_var_ID = task_loader.target_var_IDs[0][0]  # assume 1st target set and 1D\n",
    "    for task in val_tasks:\n",
    "        mean = data_processor.map_array(model.mean(task), target_var_ID, unnorm=True)\n",
    "        true = data_processor.map_array(task[\"Y_t\"][0], target_var_ID, unnorm=True)\n",
    "        errors.extend(np.abs(mean - true))\n",
    "    return np.sqrt(np.mean(np.concatenate(errors) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3aa64ca9a24ed999732cbe82556c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2b529e74ce46958d447b1cea2fb871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1644 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm_notebook(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[1;32m      9\u001b[0m     train_tasks \u001b[38;5;241m=\u001b[39m gen_training_tasks(pd\u001b[38;5;241m.\u001b[39mdate_range(train_range[\u001b[38;5;241m0\u001b[39m], train_range[\u001b[38;5;241m1\u001b[39m])[::date_subsample_factor], progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m     batch_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(batch_losses))\n\u001b[1;32m     12\u001b[0m     val_rmses\u001b[38;5;241m.\u001b[39mappend(compute_val_rmse(model, val_tasks))\n",
      "File \u001b[0;32m/mnt/SSD2/nils/deepsensor/deepsensor/train/train.py:177\u001b[0m, in \u001b[0;36mTrainer.__call__\u001b[0;34m(self, tasks, batch_size, progress_bar, tqdm_notebook)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    172\u001b[0m     tasks: List[Task],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     tqdm_notebook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_notebook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_notebook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/SSD2/nils/deepsensor/deepsensor/train/train.py:145\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, tasks, lr, batch_size, opt, progress_bar, tqdm_notebook)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         task \u001b[38;5;241m=\u001b[39m tasks[batch_i]\n\u001b[0;32m--> 145\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     batch_losses\u001b[38;5;241m.\u001b[39mappend(batch_loss)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_losses\n",
      "File \u001b[0;32m/mnt/SSD2/nils/deepsensor/deepsensor/train/train.py:116\u001b[0m, in \u001b[0;36mtrain_epoch.<locals>.train_step\u001b[0;34m(tasks)\u001b[0m\n\u001b[1;32m    114\u001b[0m task_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n\u001b[0;32m--> 116\u001b[0m     task_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    117\u001b[0m mean_batch_loss \u001b[38;5;241m=\u001b[39m B\u001b[38;5;241m.\u001b[39mmean(B\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;241m*\u001b[39mtask_losses))\n\u001b[1;32m    118\u001b[0m mean_batch_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/mnt/SSD2/nils/deepsensor/deepsensor/model/convnp.py:865\u001b[0m, in \u001b[0;36mConvNP.loss_fn\u001b[0;34m(self, task, fix_noise, num_lv_samples, normalise)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    841\u001b[0m     task: Task,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    844\u001b[0m     normalise: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    845\u001b[0m ):\n\u001b[1;32m    846\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;124;03m    Compute the loss of a task.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;124;03m        float: The loss.\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[43mConvNP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodify_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m     context_data, xt, yt, model_kwargs \u001b[38;5;241m=\u001b[39m convert_task_to_nps_args(task)\n\u001b[1;32m    869\u001b[0m     logpdfs \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mnps\u001b[38;5;241m.\u001b[39mloglik(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    871\u001b[0m         context_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    877\u001b[0m         normalise\u001b[38;5;241m=\u001b[39mnormalise,\n\u001b[1;32m    878\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/SSD2/nils/deepsensor/deepsensor/model/convnp.py:379\u001b[0m, in \u001b[0;36mConvNP.modify_task\u001b[0;34m(cls, task)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodify_task\u001b[39m(\u001b[38;5;28mcls\u001b[39m, task: Task):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Cast numpy arrays to TensorFlow or PyTorch tensors, add batch dim, and\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    mask NaNs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m        ...: ...\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mops\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    380\u001b[0m         task \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39madd_batch_dim()\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mops\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "losses = []\n",
    "val_rmses = []\n",
    "\n",
    "# Train model\n",
    "val_rmse_best = np.inf\n",
    "trainer = Trainer(model, lr=5e-5)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    train_tasks = gen_training_tasks(pd.date_range(train_range[0], train_range[1])[::date_subsample_factor], progress=True)\n",
    "    batch_losses = trainer(train_tasks)\n",
    "    losses.append(np.mean(batch_losses))\n",
    "    val_rmses.append(compute_val_rmse(model, val_tasks))\n",
    "    if val_rmses[-1] < val_rmse_best:\n",
    "        val_rmse_best = val_rmses[-1]\n",
    "        model.save(deepsensor_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(losses)\n",
    "axes[1].plot(val_rmses)\n",
    "_ = axes[0].set_xlabel(\"Epoch\")\n",
    "_ = axes[1].set_xlabel(\"Epoch\")\n",
    "_ = axes[0].set_title(\"Training loss\")\n",
    "_ = axes[1].set_title(\"Validation RMSE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensorEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
